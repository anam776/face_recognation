{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# coding: utf-8\n",
    "# In[14]:\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "# In[16]:\n",
    "img_rows = 224\n",
    "\n",
    "img_cols = 224 \n",
    "#Loads the ResNet50 model \n",
    "\n",
    "ResNet50 = ResNet50(weights = 'imagenet', \n",
    "\n",
    "                 include_top = True, \n",
    "\n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "# In[17]:\n",
    "# Print Layers\n",
    "\n",
    "for (i,layer) in enumerate(ResNet50.layers):\n",
    "\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "img_rows = 224\n",
    "\n",
    "img_cols = 224 \n",
    "\n",
    "# Re-loads the ResNet50 model without the FC layers\n",
    "ResNet50 = ResNet50(weights = 'imagenet', \n",
    "\n",
    "                 include_top = False, \n",
    "\n",
    "                 input_shape = (img_rows, img_cols, 3))\n",
    "\n",
    "\n",
    "# Here we freeze the last 4 layers \n",
    "\n",
    "# Layers are set to trainable as True by default\n",
    "\n",
    "\n",
    "\n",
    "for layer in ResNet50.layers:\n",
    "\n",
    "    layer.trainable = False\n",
    "\n",
    "# Again print the Layers\n",
    "\n",
    "\n",
    "\n",
    "for (i,layer) in enumerate(ResNet50.layers):\n",
    "\n",
    "    print(str(i) + \" \"+ layer.__class__.__name__, layer.trainable)\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "# Adding Layers to the pre-trained model\n",
    "def addTopModel(bottom_model, num_classes):\n",
    "\n",
    "    \"\"\"creates the top or head of the model that will be \n",
    "\n",
    "    placed ontop of the bottom layers\"\"\"\n",
    "\n",
    "    top_model = bottom_model.output\n",
    "\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "\n",
    "    top_model = Dense(1024,activation='relu')(top_model)\n",
    "\n",
    "    top_model = Dense(512,activation='relu')(top_model)\n",
    "\n",
    "    top_model = Dense(num_classes,activation='softmax')(top_model)\n",
    "\n",
    "    return top_model\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "\n",
    "FC_Head = addTopModel(ResNet50, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=ResNet50.input, outputs=FC_Head)\n",
    "\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# In[21]:\n",
    "# Generating new images for the same object\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_dir = './Data/Train'\n",
    "\n",
    "validation_data_dir = './Data/Validation'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "      rescale=1./255,\n",
    "\n",
    "      rotation_range=20,\n",
    "\n",
    "      width_shift_range=0.2,\n",
    "\n",
    "      height_shift_range=0.2,\n",
    "\n",
    "      horizontal_flip=True,\n",
    "\n",
    "      fill_mode='nearest')\n",
    "\n",
    " \n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_batchsize = 18\n",
    "\n",
    "val_batchsize = 20\n",
    "\n",
    " \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "        train_data_dir,\n",
    "\n",
    "        target_size=(img_rows, img_cols),\n",
    "\n",
    "        batch_size=train_batchsize,\n",
    "\n",
    "        class_mode='categorical')\n",
    "\n",
    " \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "\n",
    "        validation_data_dir,\n",
    "\n",
    "        target_size=(img_rows, img_cols),\n",
    "\n",
    "        batch_size=val_batchsize,\n",
    "\n",
    "        class_mode='categorical',\n",
    "\n",
    "        shuffle=False)\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "# importing our optimizer\n",
    "\n",
    "\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    " \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "# Training the model\n",
    "\n",
    "nb_train_samples = 140\n",
    "\n",
    "nb_validation_samples = 140\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "\n",
    "    train_generator,\n",
    "\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "\n",
    "    epochs = epochs,\n",
    "\n",
    "    validation_data = validation_generator,\n",
    "\n",
    "    validation_steps = nb_validation_samples // batch_size)\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Loading our cassifier\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "classifier = load_model('Fam_cam.h5')\n",
    "\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final step : Testing our model\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n",
    "Family_dict = {\"[0]\": \"Anam  \", \n",
    "\n",
    "                      \"[1]\": \"daggu\",\n",
    "\n",
    "                      \"[2]\": \"sister\"}\n",
    "\n",
    "\n",
    "\n",
    "Family_dict_n =  {\"n0\": \"Anam \", \n",
    "\n",
    "                         \"n1\": \"daggu\",\n",
    "\n",
    "                         \"n2\": \"sister\"}\n",
    "\n",
    "\n",
    "\n",
    "def draw_test(name, pred, im):\n",
    "\n",
    "    members = Family_dict[str(pred)]\n",
    "\n",
    "    BLACK = [0,0,0]\n",
    "\n",
    "    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "\n",
    "    cv2.putText(expanded_image, members, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "\n",
    "def getRandomImage(path):\n",
    "\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "\n",
    "    path_class = folders[random_directory]\n",
    "\n",
    "    print(\"Class - \" + Family_dict_n[str(path_class)])\n",
    "\n",
    "    file_path = path + path_class\n",
    "\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "\n",
    "    image_name = file_names[random_file_index]\n",
    "\n",
    "    return cv2.imread(file_path+\"/\"+image_name)    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "\n",
    "    input_im = getRandomImage(\"Data/Validation/\")\n",
    "\n",
    "    input_original = input_im.copy()\n",
    "\n",
    "    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    \n",
    "\n",
    "    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    input_im = input_im / 255.\n",
    "\n",
    "    input_im = input_im.reshape(1,224,224,3) \n",
    "\n",
    "    \n",
    "\n",
    "    # Show Prediction\n",
    "\n",
    "    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Show images with predicted class\n",
    "\n",
    "    draw_test(\"Fam_cam.h5\", res, input_original) \n",
    "\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    status,image = cap.read()\n",
    "    cv2.imshow('Live', image)\n",
    "    if cv2.waitKey(10)== 13:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
